{
  "tool_id": "layout_compactor",
  "pre_process_code": "import json\nfrom collections import defaultdict\nimport copy\n\ndef convert_bop_to_input(bop_json: dict, params: dict) -> str:\n    layout_nodes = []\n\n    # Map process_id to its routing info (predecessors/successors)\n    process_routing_map = {\n        p.get(\"process_id\"): p\n        for p in bop_json.get(\"processes\", [])\n        if p.get(\"process_id\")\n    }\n\n    # Map process_id to a list of its (parallel_index, node_id_string) tuples\n    # This helps in linking instances across process types for predecessor/successor lists.\n    process_instance_map = defaultdict(list)\n    \n    # First pass: Create unique node_ids for each process_detail entry.\n    # The format 'process_id-parallel_index' ensures uniqueness for each instance.\n    for detail in bop_json.get(\"process_details\", []):\n        process_id = detail.get(\"process_id\")\n        parallel_index = detail.get(\"parallel_index\", 1)\n        if not process_id:\n            continue\n        \n        node_id_str = f\"{process_id}-{parallel_index}\"\n        process_instance_map[process_id].append((parallel_index, node_id_str))\n\n    # Second pass: Build layout_nodes with full predecessor/successor lists\n    for detail in bop_json.get(\"process_details\", []):\n        process_id = detail.get(\"process_id\")\n        parallel_index = detail.get(\"parallel_index\", 1)\n        if not process_id:\n            continue\n        \n        node_id_str = f\"{process_id}-{parallel_index}\"\n        \n        location = detail.get(\"location\", {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0})\n        computed_size = detail.get(\"computed_size\", {\"width\": 1.0, \"height\": 1.0, \"depth\": 1.0})\n\n        # Get routing for the current process_id\n        routing_info = process_routing_map.get(process_id, {})\n        \n        current_node_predecessors = []\n        for pred_pid in routing_info.get(\"predecessor_ids\", []):\n            # Add ALL instances of the predecessor process as predecessors to this node instance\n            for _, pred_node_id_str in process_instance_map.get(pred_pid, []):\n                current_node_predecessors.append(pred_node_id_str)\n        \n        current_node_successors = []\n        for succ_pid in routing_info.get(\"successor_ids\", []):\n            # Add ALL instances of the successor process as successors to this node instance\n            for _, succ_node_id_str in process_instance_map.get(succ_pid, []):\n                current_node_successors.append(succ_node_id_str)\n\n        layout_nodes.append({\n            \"node_id\": node_id_str,\n            \"name\": detail.get(\"name\", node_id_str), # Use node_id_str as fallback for name\n            \"x\": location.get(\"x\", 0.0),\n            \"y\": location.get(\"y\", 0.0),\n            \"z\": location.get(\"z\", 0.0),\n            \"width\": computed_size.get(\"width\", 1.0),\n            \"depth\": computed_size.get(\"depth\", 1.0),\n            \"predecessors\": sorted(list(set(current_node_predecessors))), # Ensure unique and sorted for consistency\n            \"successors\": sorted(list(set(current_node_successors)))     # Ensure unique and sorted for consistency\n        })\n\n    tool_input = {\n        \"layout_nodes\": layout_nodes,\n        \"min_gap\": params.get(\"min_gap\", 1.5),\n        \"flow_direction\": params.get(\"flow_direction\", \"x\")\n    }\n\n    return json.dumps(tool_input, ensure_ascii=False)\n",
  "post_process_code": "import json\nimport copy\n\ndef apply_result_to_bop(bop_json: dict, tool_output: dict) -> dict:\n    # Make a deep copy of the original BOP JSON to avoid modifying it directly\n    updated_bop = copy.deepcopy(bop_json)\n\n    # Create a mapping for quick lookup of process_details by (process_id, parallel_index)\n    bop_details_map = {}\n    for detail in updated_bop.get(\"process_details\", []):\n        process_id = detail.get(\"process_id\")\n        parallel_index = detail.get(\"parallel_index\", 1)\n        if process_id:\n            bop_details_map[(process_id, parallel_index)] = detail\n            # Ensure location dict exists, with default values if not present\n            if \"location\" not in detail:\n                detail[\"location\"] = {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}\n\n    # Iterate through the compacted nodes from the tool's output\n    for compacted_node in tool_output.get(\"compacted_nodes\", []):\n        node_id = compacted_node.get(\"node_id\")\n        if not node_id:\n            continue\n\n        # Parse node_id back into process_id and parallel_index\n        # We assume the format \"PROCESSID-PARALLELINDEX\" or just \"PROCESSID\" if parallel_index is 1\n        parts = node_id.rsplit('-', 1)\n        if len(parts) == 2 and parts[1].isdigit():\n            process_id = parts[0]\n            parallel_index = int(parts[1])\n        else:\n            # If node_id does not match the expected 'ID-INDEX' format, assume parallel_index is 1\n            process_id = node_id\n            parallel_index = 1\n        \n        # Retrieve the corresponding process_detail entry from the map\n        bop_detail = bop_details_map.get((process_id, parallel_index))\n\n        if bop_detail:\n            # Update the x and z coordinates based on the compaction result.\n            # The y coordinate (height) is not modified by this layout compactor tool.\n            bop_detail[\"location\"][\"x\"] = round(compacted_node.get(\"new_x\", bop_detail[\"location\"].get(\"x\", 0.0)), 4)\n            bop_detail[\"location\"][\"z\"] = round(compacted_node.get(\"new_z\", bop_detail[\"location\"].get(\"z\", 0.0)), 4)\n\n    # Note on \"CRITICAL â€” Parallel Instance Creation Rules\":\n    # This specific Layout Compactor tool only shifts the positions of *existing* nodes.\n    # It does not introduce new process_detail instances or alter resource_assignments.\n    # Therefore, the rules regarding \"Location Offset\" and \"Resource Assignments\" for *new* instances\n    # are not applicable to this 'apply_result_to_bop' function's scope.\n\n    return updated_bop\n",
  "model": "gemini-2.5-flash",
  "generated_at": "2026-02-15T14:40:29.084970"
}