{
  "tool_id": "takt_time_optimizer",
  "pre_process_code": "import json\nimport math\nimport copy\n\ndef convert_bop_to_input(bop_json: dict, params: dict) -> str:\n    nodes = []\n    edges = []\n\n    # Map to store details for each process_id, and count parallel instances\n    # process_id -> { \"name\": ..., \"cycle_time_sec\": ..., \"instance_count\": 0 }\n    process_info = {}\n\n    # First pass: Aggregate counts and store base process info (name, cycle_time_sec)\n    for detail in bop_json.get(\"process_details\", []):\n        pid = detail.get(\"process_id\")\n        if not pid:\n            continue\n\n        if pid not in process_info:\n            # Store name and cycle_time_sec from the first instance found for this process_id\n            process_info[pid] = {\n                \"name\": detail.get(\"name\", pid),\n                \"cycle_time_sec\": detail.get(\"cycle_time_sec\", 0.0),\n                \"instance_count\": 0\n            }\n        \n        process_info[pid][\"instance_count\"] += 1\n\n    # Second pass: Create nodes from aggregated process_info\n    for pid, info in process_info.items():\n        nodes.append({\n            \"process_id\": pid,\n            \"name\": info[\"name\"],\n            \"cycle_time_sec\": info[\"cycle_time_sec\"],\n            \"current_parallel_count\": info[\"instance_count\"]\n        })\n\n    # Extract edges from processes\n    for proc in bop_json.get(\"processes\", []):\n        from_id = proc.get(\"process_id\")\n        successor_ids = proc.get(\"successor_ids\", [])\n        for to_id in successor_ids:\n            if from_id and to_id:\n                edges.append({\"from_id\": from_id, \"to_id\": to_id})\n\n    # Get user parameters, with fallbacks as defined in the 'User-Provided Parameters' section\n    target_uph = params.get(\"target_uph\")\n    if target_uph is None:\n        # Fallback to BOP's target_uph, then tool's default (60)\n        target_uph = bop_json.get(\"target_uph\", 60)\n\n    max_parallel_per_process = params.get(\"max_parallel_per_process\", 4)\n    optimization_mode = params.get(\"optimization_mode\", \"minimize_total\")\n\n    tool_input = {\n        \"process_graph\": {\n            \"nodes\": nodes,\n            \"edges\": edges\n        },\n        \"target_uph\": target_uph,\n        \"max_parallel_per_process\": max_parallel_per_process,\n        \"optimization_mode\": optimization_mode\n    }\n\n    return json.dumps(tool_input, ensure_ascii=False)\n",
  "post_process_code": "import json\nimport math\nimport copy\n\ndef apply_result_to_bop(bop_json: dict, tool_output: dict) -> dict:\n    # Use deepcopy to avoid modifying the original bop_json object directly\n    updated_bop = copy.deepcopy(bop_json) \n\n    optimized_processes_results = {\n        p[\"process_id\"]: p for p in tool_output.get(\"optimized_processes\", [])\n    }\n\n    # Group existing process_details and resource_assignments by process_id and parallel_index\n    existing_details_by_pid = {} # process_id -> list of details\n    existing_assignments_by_pid_idx = {} # (process_id, parallel_index) -> list of assignments\n\n    for detail in updated_bop.get(\"process_details\", []):\n        pid = detail.get(\"process_id\")\n        if pid:\n            existing_details_by_pid.setdefault(pid, []).append(detail)\n    \n    # Sort existing details by parallel_index for consistent base/step calculation\n    for pid in existing_details_by_pid:\n        existing_details_by_pid[pid].sort(key=lambda d: d.get(\"parallel_index\", 1))\n\n    for assignment in updated_bop.get(\"resource_assignments\", []):\n        pid = assignment.get(\"process_id\")\n        pidx = assignment.get(\"parallel_index\", 1)\n        if pid:\n            existing_assignments_by_pid_idx.setdefault((pid, pidx), []).append(assignment)\n\n    new_process_details = []\n    new_resource_assignments = []\n\n    # Iterate through optimization results to update/create/delete parallel instances\n    for pid, result in optimized_processes_results.items():\n        recommended_parallel = result.get(\"recommended_parallel\", 1)\n        \n        current_details = existing_details_by_pid.get(pid, [])\n        current_parallel_count = len(current_details)\n\n        # 1. Handle existing instances (retain or reduce)\n        # Keep up to `recommended_parallel` instances if they exist\n        for i in range(min(current_parallel_count, recommended_parallel)):\n            detail = current_details[i]\n            new_process_details.append(detail)\n            # Retain resource assignments for these kept instances\n            assignments = existing_assignments_by_pid_idx.get((pid, detail.get(\"parallel_index\", 1)), [])\n            new_resource_assignments.extend(assignments)\n\n        # 2. Add new instances if recommended_parallel > current_parallel_count\n        if recommended_parallel > current_parallel_count:\n            # A template is needed to clone properties for new instances.\n            # Based on the problem description, processes in the tool input example always start with\n            # current_parallel_count=1, so current_details[0] should always be available here.\n            template_detail = current_details[0] if current_details else None\n\n            # If no template can be found, which ideally shouldn't happen if the process was optimized,\n            # we create a minimal default to prevent errors, though its properties might not be ideal.\n            if not template_detail:\n                template_detail = {\n                    \"process_id\": pid,\n                    \"name\": pid,\n                    \"parallel_index\": 1,\n                    \"cycle_time_sec\": 0.0,\n                    \"location\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0},\n                    \"rotation_y\": 0.0,\n                    \"computed_size\": {\"width\": 1.0, \"height\": 1.0, \"depth\": 1.0}\n                }\n                # If we created a dummy template, current_parallel_count was effectively 0, so base_location will be this dummy's.\n                # The loop below will correctly add instances starting from parallel_index 1.\n                # If template_detail existed, current_parallel_count is at least 1, and loop starts from current_parallel_count.\n\n            # Calculate Z-axis offset for new instances\n            base_location = template_detail.get(\"location\", {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0})\n            z_step = 3.0 # Default offset if only one or no existing instance, or if first two are at same Z\n\n            if current_parallel_count >= 2:\n                # Calculate step from first two existing instances' Z coordinates\n                loc1 = current_details[0].get(\"location\", {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0})\n                loc2 = current_details[1].get(\"location\", {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0})\n                calculated_z_step = loc2[\"z\"] - loc1[\"z\"]\n                # Use calculated step only if it's a meaningful non-zero difference\n                if abs(calculated_z_step) > 0.001: \n                    z_step = calculated_z_step\n\n            # The loop for adding new instances should start from the next parallel index after existing ones\n            # E.g., if current_parallel_count is 1, and recommended is 2, we want to add instance with parallel_index 2.\n            # So, loop for 'i' from 'current_parallel_count' (0-indexed position) up to 'recommended_parallel - 1'.\n            for i in range(current_parallel_count, recommended_parallel):\n                new_parallel_index = i + 1 # Convert 0-indexed loop variable 'i' to 1-based parallel_index\n                new_detail = copy.deepcopy(template_detail)\n                new_detail[\"parallel_index\"] = new_parallel_index\n                \n                # Calculate new Z location for the new instance\n                # The formula (new_index - 1) * step assumes base_location corresponds to parallel_index 1\n                new_z = base_location[\"z\"] + (new_parallel_index - 1) * z_step\n                new_detail[\"location\"] = {\n                    \"x\": base_location[\"x\"],\n                    \"y\": base_location[\"y\"],\n                    \"z\": new_z\n                }\n                \n                # CRITICAL: New instances must have NO resource_assignments initially.\n                # The `new_resource_assignments` list is only populated from existing assignments\n                # of retained `process_details` instances, thus implicitly excluding new ones.\n                new_process_details.append(new_detail)\n\n    # Update the BOP structure with the newly constructed lists\n    updated_bop[\"process_details\"] = new_process_details\n    updated_bop[\"resource_assignments\"] = new_resource_assignments # This replaces the list, effectively removing assignments for deleted instances\n\n    # Update overall target_uph based on tool's achieved_uph\n    # Use achieved_uph from tool_output, fallback to existing target_uph, then 0 if none.\n    updated_bop[\"target_uph\"] = tool_output.get(\"achieved_uph\", updated_bop.get(\"target_uph\", 0))\n\n    return updated_bop",
  "model": "gemini-2.5-flash",
  "generated_at": "2026-02-15T14:50:24.532252"
}