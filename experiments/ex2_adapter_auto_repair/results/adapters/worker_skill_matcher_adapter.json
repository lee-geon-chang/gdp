{
  "tool_id": "worker_skill_matcher",
  "pre_process_code": "import json\nimport copy\n\ndef convert_bop_to_input(bop_json: dict, params: dict) -> str:\n    tool_workers = []\n    # Collect unique workers from the BOP's 'workers' list\n    # The tool expects 'worker_id', 'name', 'skill_level'\n    for worker_data in bop_json.get('workers', []):\n        tool_workers.append({\n            \"worker_id\": worker_data.get('worker_id', ''),\n            \"name\": worker_data.get('name', worker_data.get('worker_id', '')),\n            \"skill_level\": worker_data.get('skill_level', 'Mid') # Default to Mid if not specified\n        })\n\n    tool_assignments = []\n    # Collect worker assignments from BOP's 'resource_assignments'\n    # Filter for 'resource_type': 'worker'\n    # The tool expects 'process_id', 'parallel_index', 'resource_id', 'role'\n    for assignment_data in bop_json.get('resource_assignments', []):\n        if assignment_data.get('resource_type') == 'worker':\n            # BOP parallel_index is typically 1-indexed (e.g., 1, 2, 3...)\n            # Tool input example uses 0-indexed (e.g., 0, 1, 2...)\n            # Map BOP's 1-indexed to tool's 0-indexed\n            bop_parallel_index = assignment_data.get('parallel_index')\n            tool_parallel_index = 0\n            if bop_parallel_index is not None:\n                # If BOP parallel_index is 1, tool_parallel_index becomes 0.\n                # If BOP parallel_index is 2, tool_parallel_index becomes 1.\n                tool_parallel_index = max(0, bop_parallel_index - 1)\n\n            tool_assignments.append({\n                \"process_id\": assignment_data.get('process_id', ''),\n                \"parallel_index\": tool_parallel_index,\n                \"resource_id\": assignment_data.get('resource_id', ''),\n                \"role\": assignment_data.get('role', 'operator') # Default role\n            })\n    \n    # Process complexity data (from process_details)\n    # The tool expects 'process_id', 'name', 'cycle_time_sec', (optional 'complexity_level')\n    process_complexity_map = {}\n    for detail in bop_json.get('process_details', []):\n        process_id = detail.get('process_id')\n        # Only take the first instance (or any instance if parallel_index isn't consistent across details) \n        # to define the general process complexity for a given process_id, \n        # as the tool's input structure expects one entry per unique process_id.\n        if process_id and process_id not in process_complexity_map:\n            entry = {\n                \"process_id\": process_id,\n                \"name\": detail.get('name', process_id),\n                \"cycle_time_sec\": detail.get('cycle_time_sec', 60.0) # Default to 60.0 sec\n            }\n            # User parameters (params) can be used to provide explicit overrides \n            # for complexity_level, which will be passed to the tool.\n            complexity_overrides = params.get('process_complexity_overrides', {})\n            if process_id in complexity_overrides:\n                entry[\"complexity_level\"] = complexity_overrides[process_id]\n            \n            process_complexity_map[process_id] = entry\n    \n    tool_process_complexity = list(process_complexity_map.values())\n\n    # Construct the final tool input\n    tool_input = {\n        \"workers\": tool_workers,\n        \"assignments\": tool_assignments,\n        \"process_complexity\": tool_process_complexity\n    }\n    \n    # CRITICAL NOTE ON `params`:\n    # The general instructions state \"CRITICAL: Include ALL user parameters in the tool input JSON/CSV\"\n    # and provide an example of adding them as top-level fields (e.g., 'threshold': params.get('threshold')).\n    # However, the \"Tool Source Code (IMPORTANT — use exact key names from this code)\" for 'Worker Skill Matcher'\n    # explicitly only processes 'workers', 'assignments', and 'process_complexity' from its input.\n    # The \"Concrete I/O Examples (IMPORTANT — match these structures exactly)\" for tool input also\n    # strictly adheres to only these three top-level keys.\n    # Given this conflict, the specific tool's documented input structure and source code\n    # take precedence to ensure the tool receives valid input. Arbitrary 'params' would be ignored\n    # or cause errors for this particular tool. User parameters from the 'params' dict are \n    # therefore used *within* this adapter to transform the BOP data (e.g., 'process_complexity_overrides'), \n    # but not added as raw, unhandled top-level fields to the tool's input JSON.\n\n    return json.dumps(tool_input, ensure_ascii=False)\n",
  "post_process_code": "import json\nimport copy\n\ndef apply_result_to_bop(bop_json: dict, tool_output: dict) -> dict:\n    # Use copy.deepcopy to ensure the original bop_json is not modified unintentionally \n    # before the function returns the updated version.\n    updated_bop = copy.deepcopy(bop_json)\n\n    # 1. Add a new top-level key for skill matcher analysis results\n    # This aggregates the summary results from the tool's output.\n    analysis_results = {\n        \"overall_match_score\": tool_output.get(\"overall_match_score\", 0.0),\n        \"skill_distribution\": tool_output.get(\"skill_distribution\", {}),\n        \"complexity_distribution\": tool_output.get(\"complexity_distribution\", {}),\n        \"num_evaluated\": tool_output.get(\"num_evaluated\", 0),\n        \"suggestions\": tool_output.get(\"suggestions\", [])\n        # 'mismatches' could also be added here if a separate list of mismatches is desired,\n        # but 'matches' itself contains all details including score and recommendation.\n    }\n    updated_bop[\"skill_matcher_analysis\"] = analysis_results\n\n    # 2. Update individual worker resource assignments with match scores and recommendations\n    # Create a lookup dictionary for efficient access to match details by assignment key.\n    assignment_matches_lookup = {}\n    for match_entry in tool_output.get('matches', []):\n        process_id = match_entry.get('process_id')\n        tool_parallel_index = match_entry.get('parallel_index')\n        resource_id = match_entry.get('worker_id') # The tool output uses 'worker_id' for the resource_id\n\n        # Convert the tool's 0-indexed parallel_index back to BOP's 1-indexed for lookup.\n        bop_parallel_index = tool_parallel_index + 1\n\n        # Create a unique key for the assignment: (process_id, parallel_index, resource_id)\n        key = (process_id, bop_parallel_index, resource_id)\n        assignment_matches_lookup[key] = {\n            \"skill_match_score\": match_entry.get('match_score'),\n            \"skill_match_recommendation\": match_entry.get('recommendation')\n        }\n    \n    # Iterate through existing resource assignments in BOP and update worker-specific ones.\n    for assignment in updated_bop.get('resource_assignments', []):\n        if assignment.get('resource_type') == 'worker':\n            assignment_process_id = assignment.get('process_id')\n            # Default to 1 if parallel_index is missing in BOP, consistent with BOP schema examples.\n            assignment_parallel_index = assignment.get('parallel_index', 1) \n            assignment_resource_id = assignment.get('resource_id')\n            \n            lookup_key = (assignment_process_id, assignment_parallel_index, assignment_resource_id)\n\n            if lookup_key in assignment_matches_lookup:\n                match_data = assignment_matches_lookup[lookup_key]\n                assignment[\"skill_match_score\"] = match_data[\"skill_match_score\"]\n                assignment[\"skill_match_recommendation\"] = match_data[\"skill_match_recommendation\"]\n            else:\n                # For assignments not found in the tool's 'matches' (e.g., if tool filtered them),\n                # provide default/null values to indicate no specific evaluation.\n                assignment[\"skill_match_score\"] = None\n                assignment[\"skill_match_recommendation\"] = \"Assignment not evaluated or no specific match found by tool.\"\n\n    # The \"Parallel Instance Creation Rules\" mentioned in the problem description are not applicable \n    # to this specific tool's adapter as the Worker Skill Matcher only analyzes existing assignments \n    # and does not generate new process_detail instances or modify locations/sizes.\n\n    return updated_bop\n",
  "model": "gemini-2.5-flash",
  "generated_at": "2026-02-15T14:51:08.997500"
}